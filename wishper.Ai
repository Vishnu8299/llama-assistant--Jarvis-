import subprocess
import pyttsx3
import whisper
import os
import speech_recognition as sr

# Initialize the TTS engine
tts_engine = pyttsx3.init()

# Load the Whisper model
whisper_model = whisper.load_model("base")  # You can choose "small", "medium", or "large"

# Create an instance of the OllamaLLM with the model name
from langchain_ollama import OllamaLLM
model = OllamaLLM(model="llama3")

# File to store conversation history
history_file = "conversation_history.txt"

# Load conversation history from file
def load_history():
    if os.path.exists(history_file):
        with open(history_file, "r") as file:
            return file.read().splitlines()
    return []

# Save conversation history to file
def save_history(history):
    with open(history_file, "w") as file:
        for line in history:
            file.write(f"{line}\n")

# Initialize conversation history
conversation_history = load_history()

# Function to capture audio input and convert it to text using Whisper
def listen_for_audio():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("Listening...")
        audio = recognizer.listen(source)
        # Save the audio to a file
        audio_file_path = "temp_audio.wav"
        with open(audio_file_path, "wb") as file:
            file.write(audio.get_wav_data())
        
        # Use Whisper to transcribe the audio file
        result = whisper_model.transcribe(audio_file_path)
        os.remove(audio_file_path)  # Clean up the temporary file
        text = result["text"]
        
        print(f"You: {text}")
        return text

# Function to speak the output text
def speak_text(text):
    tts_engine.say(text)
    tts_engine.runAndWait()

# Function to execute system commands
def execute_command(command):
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        return result.stdout + result.stderr
    except Exception as e:
        return str(e)

# Main program loop
while True:
    # Capture audio input
    user_input = listen_for_audio()
    if user_input:
        # Update conversation history with user input
        conversation_history.append(f"User: {user_input}")

        # Combine history into a single prompt
        prompt = "\n".join(conversation_history) + "\nBot:"

        # Invoke the model with the conversation history
        result = model.invoke(input=prompt)
        print(f"Model response: {result}")

        # Update conversation history with model response
        conversation_history.append(f"Bot: {result}")

        # Check if the model's response indicates a command
        if "execute" in result.lower():
            command = result.lower().replace("execute", "").strip()
            command_output = execute_command(command)
            response = f"Executed command. Output: {command_output}"
        else:
            response = result

        # Convert the result to speech
        speak_text(response)
        
        # Save conversation history to file
        save_history(conversation_history)
